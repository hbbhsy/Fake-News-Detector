{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wrapt\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/bc/7993faa8084b5a5dbabb07a197ae1b7590da4752dc80455d878573553e2f/wrapt-1.12.0.tar.gz\n",
      "Building wheels for collected packages: wrapt\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/54/f9/95/099544e9f879f719b14cf567fabb5aa7984263df0f025f3eef\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt\n",
      "Successfully installed wrapt-1.12.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.2MB 490kB/s  eta 0:00:01    99% |████████████████████████████████| 109.1MB 108.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 2.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 25.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 40.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 52.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 47.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 68.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Collecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 39.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/97/bece4417f349f8f83252232ef66ea63eb47f8044ca61b51e2a478e2c7a94/grpcio-1.27.2-cp36-cp36m-manylinux1_x86_64.whl (2.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.7MB 19.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/72/1c1498c1e908e0562b1e1cd30012580baa7d33b5b0ffdbeb5fde2462cc71/setuptools-45.2.0-py3-none-any.whl (584kB)\n",
      "\u001b[K    100% |████████████████████████████████| 593kB 52.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 60.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Building wheels for collected packages: termcolor, absl-py\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Successfully built termcolor absl-py\n",
      "Installing collected packages: termcolor, numpy, grpcio, absl-py, setuptools, markdown, tensorboard, keras-applications, tensorflow-estimator, google-pasta, keras-preprocessing, gast, astor, tensorflow\n",
      "  Found existing installation: numpy 1.14.3\n",
      "    Uninstalling numpy-1.14.3:\n",
      "      Successfully uninstalled numpy-1.14.3\n",
      "  Found existing installation: setuptools 39.1.0\n",
      "    Uninstalling setuptools-39.1.0:\n",
      "      Successfully uninstalled setuptools-39.1.0\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.3.3 google-pasta-0.1.8 grpcio-1.27.2 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 numpy-1.18.1 setuptools-45.2.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wrapt --upgrade --ignore-installed\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-1 region. You will use the 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# NLP\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Recall, Precision\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Testing and optimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics.regression import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# import module\n",
    "from src.pipeline import *\n",
    "\n",
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "import pickle\n",
    "import datetime as dt\n",
    "import glob\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The following command must be run outside of the IPython shell:\n",
      "\n",
      "    $ pip install --upgrade pip\n",
      "\n",
      "The Python package manager (pip) can only be used from outside of IPython.\n",
      "Please reissue the `pip` command in a separate terminal or command prompt.\n",
      "\n",
      "See the Python documentation for more information on how to install packages:\n",
      "\n",
      "    https://docs.python.org/3/installing/\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = 'fakenewscorpus'\n",
    "key = 'data/news_cleaned_2018_02_13.csv'\n",
    "df = pd.read_csv('s3://{}/{}'.format(bucket,key), engine = 'python', nrows = 5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                     80\n",
       "Unnamed: 0          39999208\n",
       "id                  39999208\n",
       "domain              39999208\n",
       "type                39999208\n",
       "url                 39999208\n",
       "content             39999208\n",
       "scraped_at          39999208\n",
       "inserted_at         39999208\n",
       "updated_at          39999208\n",
       "title               39999208\n",
       "authors             39999208\n",
       "keywords            39999208\n",
       "meta_keywords       39999208\n",
       "meta_description    39999208\n",
       "tags                39999208\n",
       "summary             39999208\n",
       "source              39999208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Body, value: None, type: <class 'NoneType'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e4322b8ec07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/5M_df.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpkl_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/factory.py\u001b[0m in \u001b[0;36mdo_action\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# instance via ``self``.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdo_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/action.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parent, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     operation_name, params)\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response: %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    557\u001b[0m         }\n\u001b[1;32m    558\u001b[0m         request_dict = self._convert_to_request_dict(\n\u001b[0;32m--> 559\u001b[0;31m             api_params, operation_model, context=request_context)\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mservice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[1;32m    605\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m    606\u001b[0m         request_dict = self._serializer.serialize_to_request(\n\u001b[0;32m--> 607\u001b[0;31m             api_params, operation_model)\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host_prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                                     operation_model.input_shape)\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[1;32m    299\u001b[0m                                                      operation_model)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Body, value: None, type: <class 'NoneType'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object"
     ]
    }
   ],
   "source": [
    "import io\n",
    "pkl_buffer = io.BytesIO()\n",
    "df_key = 'data/5M_df.pkl'\n",
    "pkl_df = df.to_pickle(df_key)\n",
    "s3.Object(bucket,df_key).put(Body=pkl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = 'fakenewscorpus'\n",
    "key = 'data/5M_df.pkl'\n",
    "# obj = s3.get_object(Bucket='bucket', Key='key')\n",
    "df = pickle.loads(s3.Bucket(bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33273061724603664"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def balance(df):\n",
    "    n_pos = len(df[df['label']==1])\n",
    "    n_neg = len(df[df['label']==0])\n",
    "    return n_pos, n_neg\n",
    "\n",
    "n_pos, n_neg = balance(df)\n",
    "\n",
    "n_pos/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33258, 66742)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = pd.read_csv('data/sw1k.csv')['term'].to_numpy()\n",
    "\n",
    "sample = df.sample(100000,axis=0)\n",
    "\n",
    "balance(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenize(sample['content'],sw)\n",
    "\n",
    "sample['token']=tokens\n",
    "\n",
    "X = tokens\n",
    "y = sample['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "bow, tf, tfidf, cv, tv = vectorize(X_train,max_features=5000,ngram=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidf).to_csv('data/sample_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf = pd.read_csv('data/sample_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 5000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5466"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LENGHT = len(max(X_train, key=len))\n",
    "MAX_SEQ_LENGHT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'fsu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3f157584ab1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_FEATURES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvaries\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfastest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFORTRAN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcontiguous\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mmemory\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvaries\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfastest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'fsu'"
     ]
    }
   ],
   "source": [
    "N_FEATURES = len(bow)\n",
    "X_train_sequences = pad_sequences(X_train, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [[22], [3], [2], [1], [], [3], [5], [12], [], [7], [14], [7], [3], [5], [5], [3], [], [2], [4], [4], [22], [], [3], [], [15], [4], [15], [], [3], [2], [], [2], [3], [17], [11], [4], [8], [], [3], [5], [12], [], [2], [4], [13], [], [], [16], [3], [8], [8], [3], [20], [3], [17], [], [20], [3], [7], [], [8], [1], [15], [4], [8], [2], [6], [5], [16], [], [2], [9], [1], [], [5], [1], [20], [7], [], [], [3], [5], [5], [4], [14], [5], [10], [6], [5], [16], [], [2], [9], [3], [2], [], [7], [20], [6], [18], [2], [], [9], [3], [7], [], [19], [1], [1], [5], [], [14], [5], [18], [4], [11], [11], [4], [20], [1], [12], [], [19], [17], [], [9], [1], [8], [], [1], [28], [], [19], [4], [17], [18], [8], [6], [1], [5], [12], [], [10], [3], [11], [21], [6], [5], [], [9], [3], [8], [8], [6], [7], [], [4], [5], [], [2], [20], [6], [2], [2], [1], [8], [], [], [], [8], [1], [15], [4], [8], [2], [7], [], [9], [3], [21], [1], [], [7], [14], [8], [18], [3], [10], [1], [12], [], [4], [21], [1], [8], [5], [6], [16], [9], [2], [], [2], [9], [3], [2], [], [2], [9], [1], [], [15], [4], [15], [], [7], [2], [3], [8], [7], [], [], [], [20], [9], [4], [], [3], [5], [5], [4], [14], [5], [10], [1], [12], [], [2], [9], [1], [6], [8], [], [19], [8], [1], [3], [22], [], [14], [15], [], [3], [5], [12], [], [6], [5], [7], [6], [7], [2], [1], [12], [], [6], [2], [], [20], [3], [7], [], [3], [13], [6], [10], [3], [19], [11], [1], [], [11], [3], [7], [2], [], [20], [1], [1], [22], [], [], [], [9], [3], [21], [1], [], [18], [3], [11], [11], [1], [5], [], [4], [14], [2], [], [19], [1], [10], [3], [14], [7], [1], [], [7], [20], [6], [18], [2], [], [9], [3], [7], [], [19], [1], [1], [5], [], [10], [3], [14], [16], [9], [2], [], [10], [4], [7], [17], [6], [5], [16], [], [14], [15], [], [2], [4], [], [2], [9], [1], [], [5], [6], [16], [9], [2], [], [13], [3], [5], [3], [16], [1], [8], [], [3], [10], [2], [4], [8], [], [3], [5], [12], [], [24], [3], [13], [1], [7], [], [19], [4], [5], [12], [], [9], [4], [15], [1], [18], [14], [11], [], [2], [4], [13], [], [9], [6], [12], [12], [11], [1], [7], [2], [4], [5], [], [], [], [2], [9], [1], [8], [1], [], [9], [3], [7], [], [19], [1], [1], [5], [], [5], [4], [], [10], [4], [5], [18], [6], [8], [13], [3], [2], [6], [4], [5], [], [3], [7], [], [4], [18], [], [17], [1], [2], [], [], [19], [14], [2], [], [16], [3], [8], [8], [3], [20], [3], [17], [], [20], [3], [7], [], [35], [14], [6], [10], [22], [], [2], [4], [], [16], [6], [21], [1], [], [9], [1], [8], [], [4], [15], [6], [5], [6], [4], [5], [], [], [], [36], [7], [9], [1], [], [], [7], [20], [6], [18], [2], [], [], [6], [7], [5], [27], [2], [], [16], [4], [6], [5], [16], [], [2], [4], [], [19], [1], [], [7], [9], [4], [8], [2], [], [4], [18], [], [4], [18], [18], [1], [8], [7], [], [37], [], [2], [9], [1], [], [], [], [], [17], [1], [3], [8], [], [4], [11], [12], [], [15], [8], [1], [7], [1], [5], [2], [1], [8], [], [7], [3], [6], [12], [], [], [36], [20], [9], [17], [], [10], [3], [5], [27], [2], [], [7], [9], [1], [], [24], [14], [7], [2], [], [11], [1], [3], [21], [1], [], [2], [4], [13], [], [9], [6], [12], [12], [11], [1], [7], [2], [4], [5], [], [3], [11], [4], [5], [1], [], [18], [4], [8], [], [14], [7], [], [37]] \n",
      "\n",
      "word_index :  {'e': 1, 't': 2, 'a': 3, 'o': 4, 'n': 5, 'i': 6, 's': 7, 'r': 8, 'h': 9, 'c': 10, 'l': 11, 'd': 12, 'm': 13, 'u': 14, 'p': 15, 'g': 16, 'y': 17, 'f': 18, 'b': 19, 'w': 20, 'v': 21, 'k': 22, \"'\": 23, 'j': 24, '1': 25, '2': 26, '’': 27, 'x': 28, '3': 29, 'z': 30, '0': 31, '8': 32, '6': 33, '5': 34, 'q': 35, '“': 36, '”': 37, '…': 38, '‘': 39}\n"
     ]
    }
   ],
   "source": [
    "t_temp = Tokenizer(num_words = 500)\n",
    "s = sample['content']\n",
    "t_temp.fit_on_texts(s)\n",
    " = t_temp.texts_to_sequences(r)\n",
    "print('sequences : ', sq,'\\n')\n",
    "print('word_index : ',t_temp.word_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample['content']\n",
    "y = sample['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 500)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Tokenizer(num_words=5000)\n",
    "t.fit_on_texts(sample['content'])\n",
    "X = t.texts_to_sequences(sample['content'])\n",
    "X = pad_sequences(X, maxlen=500)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 1, 128)            322048    \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 453,761\n",
      "Trainable params: 453,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "# model.add(Embedding(5000 + 1,\n",
    "#                     64  # Embedding size\n",
    "#                    ))\n",
    "\n",
    "model3.add(LSTM(units=128, return_sequences=True, input_shape=(1,500)))\n",
    "model3.add(LSTM(128),)\n",
    "model3.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC','BinaryAccuracy','Recall','Precision'])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65000 samples, validate on 10000 samples\n",
      "Epoch 1/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5601 - auc_10: 0.7130 - binary_accuracy: 0.7130 - recall_6: 0.3046 - precision_6: 0.6452 - val_loss: 0.5839 - val_auc_10: 0.6847 - val_binary_accuracy: 0.6992 - val_recall_6: 0.3110 - val_precision_6: 0.5982\n",
      "Epoch 2/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5594 - auc_10: 0.7129 - binary_accuracy: 0.7123 - recall_6: 0.3037 - precision_6: 0.6432 - val_loss: 0.5825 - val_auc_10: 0.6854 - val_binary_accuracy: 0.7005 - val_recall_6: 0.2678 - val_precision_6: 0.6233\n",
      "Epoch 3/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5602 - auc_10: 0.7132 - binary_accuracy: 0.7111 - recall_6: 0.3048 - precision_6: 0.6376 - val_loss: 0.5792 - val_auc_10: 0.6911 - val_binary_accuracy: 0.6996 - val_recall_6: 0.2543 - val_precision_6: 0.6274\n",
      "Epoch 4/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5592 - auc_10: 0.7146 - binary_accuracy: 0.7110 - recall_6: 0.2975 - precision_6: 0.6415 - val_loss: 0.5822 - val_auc_10: 0.6856 - val_binary_accuracy: 0.6969 - val_recall_6: 0.2901 - val_precision_6: 0.5982\n",
      "Epoch 5/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5590 - auc_10: 0.7135 - binary_accuracy: 0.7123 - recall_6: 0.2971 - precision_6: 0.6469 - val_loss: 0.5796 - val_auc_10: 0.6901 - val_binary_accuracy: 0.6974 - val_recall_6: 0.2600 - val_precision_6: 0.6142\n",
      "Epoch 6/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5574 - auc_10: 0.7163 - binary_accuracy: 0.7129 - recall_6: 0.2998 - precision_6: 0.6480 - val_loss: 0.5817 - val_auc_10: 0.6891 - val_binary_accuracy: 0.6978 - val_recall_6: 0.2830 - val_precision_6: 0.6046\n",
      "Epoch 7/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5565 - auc_10: 0.7177 - binary_accuracy: 0.7140 - recall_6: 0.2973 - precision_6: 0.6544 - val_loss: 0.5814 - val_auc_10: 0.6911 - val_binary_accuracy: 0.6966 - val_recall_6: 0.3087 - val_precision_6: 0.5902\n",
      "Epoch 8/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5572 - auc_10: 0.7162 - binary_accuracy: 0.7133 - recall_6: 0.2996 - precision_6: 0.6496 - val_loss: 0.5807 - val_auc_10: 0.6895 - val_binary_accuracy: 0.7024 - val_recall_6: 0.2872 - val_precision_6: 0.6206\n",
      "Epoch 9/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5582 - auc_10: 0.7142 - binary_accuracy: 0.7114 - recall_6: 0.3010 - precision_6: 0.6407 - val_loss: 0.5842 - val_auc_10: 0.6872 - val_binary_accuracy: 0.7007 - val_recall_6: 0.2549 - val_precision_6: 0.6321\n",
      "Epoch 10/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5581 - auc_10: 0.7147 - binary_accuracy: 0.7128 - recall_6: 0.3040 - precision_6: 0.6447 - val_loss: 0.5808 - val_auc_10: 0.6879 - val_binary_accuracy: 0.7000 - val_recall_6: 0.2854 - val_precision_6: 0.6120\n",
      "Epoch 11/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5585 - auc_10: 0.7144 - binary_accuracy: 0.7123 - recall_6: 0.2994 - precision_6: 0.6456 - val_loss: 0.5799 - val_auc_10: 0.6895 - val_binary_accuracy: 0.7007 - val_recall_6: 0.2475 - val_precision_6: 0.6372\n",
      "Epoch 12/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5570 - auc_10: 0.7146 - binary_accuracy: 0.7136 - recall_6: 0.3027 - precision_6: 0.6490 - val_loss: 0.5781 - val_auc_10: 0.6907 - val_binary_accuracy: 0.6973 - val_recall_6: 0.2884 - val_precision_6: 0.6004\n",
      "Epoch 13/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5566 - auc_10: 0.7156 - binary_accuracy: 0.7143 - recall_6: 0.3069 - precision_6: 0.6491 - val_loss: 0.5795 - val_auc_10: 0.6897 - val_binary_accuracy: 0.6967 - val_recall_6: 0.3131 - val_precision_6: 0.5890\n",
      "Epoch 14/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5561 - auc_10: 0.7175 - binary_accuracy: 0.7145 - recall_6: 0.2967 - precision_6: 0.6568 - val_loss: 0.5805 - val_auc_10: 0.6911 - val_binary_accuracy: 0.6989 - val_recall_6: 0.2869 - val_precision_6: 0.6071\n",
      "Epoch 15/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5559 - auc_10: 0.7187 - binary_accuracy: 0.7146 - recall_6: 0.3035 - precision_6: 0.6526 - val_loss: 0.5828 - val_auc_10: 0.6906 - val_binary_accuracy: 0.6931 - val_recall_6: 0.3361 - val_precision_6: 0.5713\n",
      "Epoch 16/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5556 - auc_10: 0.7193 - binary_accuracy: 0.7135 - recall_6: 0.3101 - precision_6: 0.6442 - val_loss: 0.5827 - val_auc_10: 0.6887 - val_binary_accuracy: 0.6995 - val_recall_6: 0.3030 - val_precision_6: 0.6024\n",
      "Epoch 17/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5544 - auc_10: 0.7201 - binary_accuracy: 0.7138 - recall_6: 0.3091 - precision_6: 0.6459 - val_loss: 0.5779 - val_auc_10: 0.6917 - val_binary_accuracy: 0.7007 - val_recall_6: 0.2860 - val_precision_6: 0.6145\n",
      "Epoch 18/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5555 - auc_10: 0.7185 - binary_accuracy: 0.7137 - recall_6: 0.3081 - precision_6: 0.6462 - val_loss: 0.5820 - val_auc_10: 0.6868 - val_binary_accuracy: 0.6998 - val_recall_6: 0.2896 - val_precision_6: 0.6093\n",
      "Epoch 19/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5547 - auc_10: 0.7190 - binary_accuracy: 0.7132 - recall_6: 0.3087 - precision_6: 0.6436 - val_loss: 0.5804 - val_auc_10: 0.6891 - val_binary_accuracy: 0.7000 - val_recall_6: 0.2734 - val_precision_6: 0.6181\n",
      "Epoch 20/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5544 - auc_10: 0.7187 - binary_accuracy: 0.7151 - recall_6: 0.3086 - precision_6: 0.6514 - val_loss: 0.5811 - val_auc_10: 0.6901 - val_binary_accuracy: 0.6995 - val_recall_6: 0.2785 - val_precision_6: 0.6134\n",
      "Epoch 21/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5540 - auc_10: 0.7196 - binary_accuracy: 0.7152 - recall_6: 0.3021 - precision_6: 0.6562 - val_loss: 0.5806 - val_auc_10: 0.6893 - val_binary_accuracy: 0.7021 - val_recall_6: 0.2531 - val_precision_6: 0.6400\n",
      "Epoch 22/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5531 - auc_10: 0.7212 - binary_accuracy: 0.7169 - recall_6: 0.3049 - precision_6: 0.6614 - val_loss: 0.5816 - val_auc_10: 0.6872 - val_binary_accuracy: 0.6927 - val_recall_6: 0.3325 - val_precision_6: 0.5710\n",
      "Epoch 23/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5539 - auc_10: 0.7199 - binary_accuracy: 0.7148 - recall_6: 0.3043 - precision_6: 0.6528 - val_loss: 0.5822 - val_auc_10: 0.6924 - val_binary_accuracy: 0.7000 - val_recall_6: 0.2785 - val_precision_6: 0.6154\n",
      "Epoch 24/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5532 - auc_10: 0.7202 - binary_accuracy: 0.7163 - recall_6: 0.3110 - precision_6: 0.6548 - val_loss: 0.5782 - val_auc_10: 0.6937 - val_binary_accuracy: 0.6993 - val_recall_6: 0.2955 - val_precision_6: 0.6048\n",
      "Epoch 25/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5520 - auc_10: 0.7227 - binary_accuracy: 0.7166 - recall_6: 0.3178 - precision_6: 0.6516 - val_loss: 0.5794 - val_auc_10: 0.6929 - val_binary_accuracy: 0.7001 - val_recall_6: 0.2746 - val_precision_6: 0.6179\n",
      "Epoch 26/43\n",
      "65000/65000 [==============================] - 2s 35us/sample - loss: 0.5514 - auc_10: 0.7234 - binary_accuracy: 0.7163 - recall_6: 0.3171 - precision_6: 0.6511 - val_loss: 0.5823 - val_auc_10: 0.6911 - val_binary_accuracy: 0.6949 - val_recall_6: 0.3301 - val_precision_6: 0.5781\n",
      "Epoch 27/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5514 - auc_10: 0.7233 - binary_accuracy: 0.7162 - recall_6: 0.3120 - precision_6: 0.6539 - val_loss: 0.5815 - val_auc_10: 0.6932 - val_binary_accuracy: 0.6977 - val_recall_6: 0.2994 - val_precision_6: 0.5974\n",
      "Epoch 28/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5521 - auc_10: 0.7235 - binary_accuracy: 0.7158 - recall_6: 0.3074 - precision_6: 0.6551 - val_loss: 0.5804 - val_auc_10: 0.6924 - val_binary_accuracy: 0.6970 - val_recall_6: 0.2925 - val_precision_6: 0.5976\n",
      "Epoch 29/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5527 - auc_10: 0.7230 - binary_accuracy: 0.7144 - recall_6: 0.3076 - precision_6: 0.6493 - val_loss: 0.5813 - val_auc_10: 0.6912 - val_binary_accuracy: 0.6977 - val_recall_6: 0.2516 - val_precision_6: 0.6203\n",
      "Epoch 30/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5524 - auc_10: 0.7238 - binary_accuracy: 0.7156 - recall_6: 0.3093 - precision_6: 0.6529 - val_loss: 0.5814 - val_auc_10: 0.6903 - val_binary_accuracy: 0.6991 - val_recall_6: 0.2970 - val_precision_6: 0.6034\n",
      "Epoch 31/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5528 - auc_10: 0.7229 - binary_accuracy: 0.7144 - recall_6: 0.3173 - precision_6: 0.6435 - val_loss: 0.5814 - val_auc_10: 0.6893 - val_binary_accuracy: 0.6959 - val_recall_6: 0.3039 - val_precision_6: 0.5895\n",
      "Epoch 32/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5517 - auc_10: 0.7230 - binary_accuracy: 0.7158 - recall_6: 0.3135 - precision_6: 0.6514 - val_loss: 0.5789 - val_auc_10: 0.6931 - val_binary_accuracy: 0.6957 - val_recall_6: 0.2913 - val_precision_6: 0.5933\n",
      "Epoch 33/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5503 - auc_10: 0.7249 - binary_accuracy: 0.7177 - recall_6: 0.3104 - precision_6: 0.6610 - val_loss: 0.5801 - val_auc_10: 0.6934 - val_binary_accuracy: 0.6978 - val_recall_6: 0.2979 - val_precision_6: 0.5983\n",
      "Epoch 34/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5501 - auc_10: 0.7253 - binary_accuracy: 0.7171 - recall_6: 0.3092 - precision_6: 0.6592 - val_loss: 0.5803 - val_auc_10: 0.6940 - val_binary_accuracy: 0.6996 - val_recall_6: 0.2812 - val_precision_6: 0.6125\n",
      "Epoch 35/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5491 - auc_10: 0.7268 - binary_accuracy: 0.7190 - recall_6: 0.3127 - precision_6: 0.6652 - val_loss: 0.5826 - val_auc_10: 0.6896 - val_binary_accuracy: 0.6976 - val_recall_6: 0.2943 - val_precision_6: 0.5990\n",
      "Epoch 36/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5483 - auc_10: 0.7269 - binary_accuracy: 0.7199 - recall_6: 0.3261 - precision_6: 0.6599 - val_loss: 0.5841 - val_auc_10: 0.6887 - val_binary_accuracy: 0.6930 - val_recall_6: 0.2928 - val_precision_6: 0.5832\n",
      "Epoch 37/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5477 - auc_10: 0.7280 - binary_accuracy: 0.7198 - recall_6: 0.3231 - precision_6: 0.6615 - val_loss: 0.5827 - val_auc_10: 0.6913 - val_binary_accuracy: 0.6963 - val_recall_6: 0.2866 - val_precision_6: 0.5974\n",
      "Epoch 38/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5470 - auc_10: 0.7292 - binary_accuracy: 0.7206 - recall_6: 0.3248 - precision_6: 0.6635 - val_loss: 0.5860 - val_auc_10: 0.6862 - val_binary_accuracy: 0.6920 - val_recall_6: 0.3337 - val_precision_6: 0.5687\n",
      "Epoch 39/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5483 - auc_10: 0.7271 - binary_accuracy: 0.7200 - recall_6: 0.3286 - precision_6: 0.6584 - val_loss: 0.5839 - val_auc_10: 0.6903 - val_binary_accuracy: 0.6972 - val_recall_6: 0.2648 - val_precision_6: 0.6109\n",
      "Epoch 40/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5473 - auc_10: 0.7270 - binary_accuracy: 0.7207 - recall_6: 0.3239 - precision_6: 0.6643 - val_loss: 0.5823 - val_auc_10: 0.6902 - val_binary_accuracy: 0.6999 - val_recall_6: 0.2839 - val_precision_6: 0.6124\n",
      "Epoch 41/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5479 - auc_10: 0.7272 - binary_accuracy: 0.7197 - recall_6: 0.3262 - precision_6: 0.6588 - val_loss: 0.5835 - val_auc_10: 0.6911 - val_binary_accuracy: 0.7010 - val_recall_6: 0.3412 - val_precision_6: 0.5935\n",
      "Epoch 42/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5467 - auc_10: 0.7286 - binary_accuracy: 0.7211 - recall_6: 0.3282 - precision_6: 0.6633 - val_loss: 0.5813 - val_auc_10: 0.6914 - val_binary_accuracy: 0.7011 - val_recall_6: 0.2794 - val_precision_6: 0.6195\n",
      "Epoch 43/43\n",
      "65000/65000 [==============================] - 2s 34us/sample - loss: 0.5470 - auc_10: 0.7272 - binary_accuracy: 0.7201 - recall_6: 0.3199 - precision_6: 0.6648 - val_loss: 0.5839 - val_auc_10: 0.6909 - val_binary_accuracy: 0.7002 - val_recall_6: 0.3000 - val_precision_6: 0.6062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2742c6d9b0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train[:-10000], y_train[:-10000], \n",
    "          epochs=43, batch_size=128, verbose=1,\n",
    "          validation_data=(X_train[-10000:], y_train[-10000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/sample_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('saved_model/sample_model',compile = False)\n",
    "tfidf = pd.read_csv('data/sample_tfidf.csv')\n",
    "X_train = tfidf.set_ind\n",
    "y_train = sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.save('saved_model/sample_model3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [' '.join(row) for row in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 37s 15ms/sample - loss: 0.6377 - auc_14: 0.5000 - binary_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.637664122581482, 0.5, 0.6656]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 2,501,001\n",
      "Trainable params: 2,501,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    " \n",
    "model2.add(Dense(units=500, activation='relu', input_dim=5000))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC','BinaryAccuracy','Recall','Precision'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "65000/65000 [==============================] - 4s 56us/sample - loss: 0.3315 - auc_2: 0.9143 - binary_accuracy: 0.8586 - recall: 0.6843 - precision: 0.8681 - val_loss: 0.2754 - val_auc_2: 0.9386 - val_binary_accuracy: 0.8855 - val_recall: 0.7291 - val_precision: 0.9064\n",
      "Epoch 2/30\n",
      "65000/65000 [==============================] - 3s 51us/sample - loss: 0.2491 - auc_2: 0.9514 - binary_accuracy: 0.8976 - recall: 0.7859 - precision: 0.8975 - val_loss: 0.2642 - val_auc_2: 0.9423 - val_binary_accuracy: 0.8889 - val_recall: 0.7557 - val_precision: 0.8919\n",
      "Epoch 3/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.2161 - auc_2: 0.9637 - binary_accuracy: 0.9110 - recall: 0.8133 - precision: 0.9133 - val_loss: 0.2657 - val_auc_2: 0.9431 - val_binary_accuracy: 0.8889 - val_recall: 0.7884 - val_precision: 0.8639\n",
      "Epoch 4/30\n",
      "65000/65000 [==============================] - 3s 53us/sample - loss: 0.1778 - auc_2: 0.9763 - binary_accuracy: 0.9300 - recall: 0.8503 - precision: 0.9361 - val_loss: 0.2706 - val_auc_2: 0.9440 - val_binary_accuracy: 0.8905 - val_recall: 0.7884 - val_precision: 0.8685\n",
      "Epoch 5/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.1342 - auc_2: 0.9873 - binary_accuracy: 0.9526 - recall: 0.8970 - precision: 0.9598 - val_loss: 0.2783 - val_auc_2: 0.9443 - val_binary_accuracy: 0.8901 - val_recall: 0.7963 - val_precision: 0.8611\n",
      "Epoch 6/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0886 - auc_2: 0.9950 - binary_accuracy: 0.9753 - recall: 0.9443 - precision: 0.9818 - val_loss: 0.3010 - val_auc_2: 0.9430 - val_binary_accuracy: 0.8897 - val_recall: 0.8029 - val_precision: 0.8548\n",
      "Epoch 7/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0532 - auc_2: 0.9982 - binary_accuracy: 0.9893 - recall: 0.9733 - precision: 0.9947 - val_loss: 0.3173 - val_auc_2: 0.9410 - val_binary_accuracy: 0.8927 - val_recall: 0.7947 - val_precision: 0.8697\n",
      "Epoch 8/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0310 - auc_2: 0.9994 - binary_accuracy: 0.9951 - recall: 0.9864 - precision: 0.9990 - val_loss: 0.3489 - val_auc_2: 0.9386 - val_binary_accuracy: 0.8925 - val_recall: 0.7929 - val_precision: 0.8706\n",
      "Epoch 9/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0193 - auc_2: 0.9998 - binary_accuracy: 0.9968 - recall: 0.9910 - precision: 0.9994 - val_loss: 0.3660 - val_auc_2: 0.9374 - val_binary_accuracy: 0.8912 - val_recall: 0.8023 - val_precision: 0.8595\n",
      "Epoch 10/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0133 - auc_2: 0.9999 - binary_accuracy: 0.9973 - recall: 0.9925 - precision: 0.9995 - val_loss: 0.3973 - val_auc_2: 0.9356 - val_binary_accuracy: 0.8896 - val_recall: 0.8083 - val_precision: 0.8505\n",
      "Epoch 11/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0102 - auc_2: 0.9999 - binary_accuracy: 0.9975 - recall: 0.9931 - precision: 0.9996 - val_loss: 0.4181 - val_auc_2: 0.9329 - val_binary_accuracy: 0.8899 - val_recall: 0.8077 - val_precision: 0.8518\n",
      "Epoch 12/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0086 - auc_2: 0.9999 - binary_accuracy: 0.9977 - recall: 0.9934 - precision: 0.9997 - val_loss: 0.4423 - val_auc_2: 0.9307 - val_binary_accuracy: 0.8898 - val_recall: 0.8047 - val_precision: 0.8538\n",
      "Epoch 13/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0075 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9936 - precision: 0.9999 - val_loss: 0.4604 - val_auc_2: 0.9285 - val_binary_accuracy: 0.8904 - val_recall: 0.8056 - val_precision: 0.8547\n",
      "Epoch 14/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0070 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9936 - precision: 0.9999 - val_loss: 0.4726 - val_auc_2: 0.9287 - val_binary_accuracy: 0.8894 - val_recall: 0.8117 - val_precision: 0.8475\n",
      "Epoch 15/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0066 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9937 - precision: 0.9999 - val_loss: 0.4904 - val_auc_2: 0.9278 - val_binary_accuracy: 0.8886 - val_recall: 0.8096 - val_precision: 0.8469\n",
      "Epoch 16/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0063 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9937 - precision: 0.9999 - val_loss: 0.5151 - val_auc_2: 0.9243 - val_binary_accuracy: 0.8926 - val_recall: 0.7963 - val_precision: 0.8682\n",
      "Epoch 17/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0060 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5225 - val_auc_2: 0.9244 - val_binary_accuracy: 0.8920 - val_recall: 0.8008 - val_precision: 0.8629\n",
      "Epoch 18/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0059 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5355 - val_auc_2: 0.9237 - val_binary_accuracy: 0.8910 - val_recall: 0.8035 - val_precision: 0.8580\n",
      "Epoch 19/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0058 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5525 - val_auc_2: 0.9217 - val_binary_accuracy: 0.8927 - val_recall: 0.8029 - val_precision: 0.8632\n",
      "Epoch 20/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0058 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 0.9999 - val_loss: 0.5601 - val_auc_2: 0.9224 - val_binary_accuracy: 0.8910 - val_recall: 0.8053 - val_precision: 0.8566\n",
      "Epoch 21/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5750 - val_auc_2: 0.9205 - val_binary_accuracy: 0.8920 - val_recall: 0.8053 - val_precision: 0.8594\n",
      "Epoch 22/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5818 - val_auc_2: 0.9196 - val_binary_accuracy: 0.8913 - val_recall: 0.8029 - val_precision: 0.8593\n",
      "Epoch 23/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5880 - val_auc_2: 0.9200 - val_binary_accuracy: 0.8905 - val_recall: 0.8080 - val_precision: 0.8532\n",
      "Epoch 24/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0132 - auc_2: 0.9997 - binary_accuracy: 0.9954 - recall: 0.9901 - precision: 0.9963 - val_loss: 0.5385 - val_auc_2: 0.9189 - val_binary_accuracy: 0.8848 - val_recall: 0.7947 - val_precision: 0.8475\n",
      "Epoch 25/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0111 - auc_2: 0.9999 - binary_accuracy: 0.9966 - recall: 0.9920 - precision: 0.9980 - val_loss: 0.5462 - val_auc_2: 0.9218 - val_binary_accuracy: 0.8874 - val_recall: 0.8035 - val_precision: 0.8481\n",
      "Epoch 26/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0061 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5754 - val_auc_2: 0.9189 - val_binary_accuracy: 0.8910 - val_recall: 0.7963 - val_precision: 0.8636\n",
      "Epoch 27/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 1.0000 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5954 - val_auc_2: 0.9174 - val_binary_accuracy: 0.8913 - val_recall: 0.7956 - val_precision: 0.8649\n",
      "Epoch 28/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6070 - val_auc_2: 0.9167 - val_binary_accuracy: 0.8917 - val_recall: 0.7975 - val_precision: 0.8646\n",
      "Epoch 29/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0056 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6153 - val_auc_2: 0.9165 - val_binary_accuracy: 0.8913 - val_recall: 0.8005 - val_precision: 0.8611\n",
      "Epoch 30/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0056 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6179 - val_auc_2: 0.9176 - val_binary_accuracy: 0.8897 - val_recall: 0.8050 - val_precision: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87905ce390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(tfidf[:-10000], y_train[:-10000], \n",
    "          epochs=30, batch_size=128, verbose=1,\n",
    "          validation_data=(tfidf[-10000:], y_train[-10000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('saved_model/sample_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 59us/sample - loss: 0.6468 - auc_2: 0.9164 - binary_accuracy: 0.8898 - recall: 0.8058 - precision: 0.8510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6467978135927022, 0.9164012, 0.88976, 0.8058158, 0.8509572]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = 0.81"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
