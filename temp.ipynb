{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wrapt\n",
      "  Downloading https://files.pythonhosted.org/packages/ee/bc/7993faa8084b5a5dbabb07a197ae1b7590da4752dc80455d878573553e2f/wrapt-1.12.0.tar.gz\n",
      "Building wheels for collected packages: wrapt\n",
      "  Running setup.py bdist_wheel for wrapt ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/54/f9/95/099544e9f879f719b14cf567fabb5aa7984263df0f025f3eef\n",
      "Successfully built wrapt\n",
      "Installing collected packages: wrapt\n",
      "Successfully installed wrapt-1.12.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 109.2MB 499kB/s  eta 0:00:01  11% |███▋                            | 12.3MB 93.2MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 35.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.31.1)\n",
      "Collecting tensorboard<1.15.0,>=1.14.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 17.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 37.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 42.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/97/bece4417f349f8f83252232ef66ea63eb47f8044ca61b51e2a478e2c7a94/grpcio-1.27.2-cp36-cp36m-manylinux1_x86_64.whl (2.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.7MB 22.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
      "Collecting numpy<2.0,>=1.14.5 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 2.6MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.6.1)\n",
      "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
      "\u001b[K    100% |████████████████████████████████| 491kB 51.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.7.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 66.9MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c4/ba46d44855e6eb1770a12edace5a165a0c6de13349f592b9036257f3c3d3/Markdown-3.2.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 50.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.14.1)\n",
      "Collecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/72/1c1498c1e908e0562b1e1cd30012580baa7d33b5b0ffdbeb5fde2462cc71/setuptools-45.2.0-py3-none-any.whl (584kB)\n",
      "\u001b[K    100% |████████████████████████████████| 593kB 45.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Building wheels for collected packages: termcolor, absl-py\n",
      "  Running setup.py bdist_wheel for termcolor ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/8e/28/49/fad4e7f0b9a1227708cbbee4487ac8558a7334849cb81c813d\n",
      "Successfully built termcolor absl-py\n",
      "Installing collected packages: numpy, keras-preprocessing, termcolor, setuptools, markdown, grpcio, absl-py, tensorboard, keras-applications, google-pasta, gast, astor, tensorflow-estimator, tensorflow\n",
      "  Found existing installation: numpy 1.14.3\n",
      "    Uninstalling numpy-1.14.3:\n",
      "      Successfully uninstalled numpy-1.14.3\n",
      "  Found existing installation: setuptools 39.1.0\n",
      "    Uninstalling setuptools-39.1.0:\n",
      "      Successfully uninstalled setuptools-39.1.0\n",
      "Successfully installed absl-py-0.9.0 astor-0.8.1 gast-0.3.3 google-pasta-0.1.8 grpcio-1.27.2 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.2.1 numpy-1.18.1 setuptools-45.2.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install wrapt --upgrade --ignore-installed\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_treebank_pos_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-1 region. You will use the 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# NLP\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# TensorFlow and Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy, Recall, Precision\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Testing and optimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics.regression import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# import module\n",
    "from src.pipeline import *\n",
    "\n",
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "import pickle\n",
    "import datetime as dt\n",
    "import glob\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/DEMO-xgboost-dm'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from s3 bucket\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = 'fakenewscorpus'\n",
    "key = 'data/news_cleaned_2018_02_13.csv'\n",
    "df = pd.read_csv('s3://{}/{}'.format(bucket,key), engine = 'python', nrows = 5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index                     80\n",
       "Unnamed: 0          39999208\n",
       "id                  39999208\n",
       "domain              39999208\n",
       "type                39999208\n",
       "url                 39999208\n",
       "content             39999208\n",
       "scraped_at          39999208\n",
       "inserted_at         39999208\n",
       "updated_at          39999208\n",
       "title               39999208\n",
       "authors             39999208\n",
       "keywords            39999208\n",
       "meta_keywords       39999208\n",
       "meta_description    39999208\n",
       "tags                39999208\n",
       "summary             39999208\n",
       "source              39999208\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ParamValidationError",
     "evalue": "Parameter validation failed:\nInvalid type for parameter Body, value: None, type: <class 'NoneType'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParamValidationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e4322b8ec07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/5M_df.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpkl_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ms3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpkl_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/factory.py\u001b[0m in \u001b[0;36mdo_action\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0;31m# instance via ``self``.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdo_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/resources/action.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parent, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m                     operation_name, params)\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response: %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    275\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    557\u001b[0m         }\n\u001b[1;32m    558\u001b[0m         request_dict = self._convert_to_request_dict(\n\u001b[0;32m--> 559\u001b[0;31m             api_params, operation_model, context=request_context)\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mservice_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_service_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mservice_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_convert_to_request_dict\u001b[0;34m(self, api_params, operation_model, context)\u001b[0m\n\u001b[1;32m    605\u001b[0m             api_params, operation_model, context)\n\u001b[1;32m    606\u001b[0m         request_dict = self._serializer.serialize_to_request(\n\u001b[0;32m--> 607\u001b[0;31m             api_params, operation_model)\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_host_prefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m             \u001b[0mrequest_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'host_prefix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/botocore/validate.py\u001b[0m in \u001b[0;36mserialize_to_request\u001b[0;34m(self, parameters, operation_model)\u001b[0m\n\u001b[1;32m    295\u001b[0m                                                     operation_model.input_shape)\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mParamValidationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         return self._serializer.serialize_to_request(parameters,\n\u001b[1;32m    299\u001b[0m                                                      operation_model)\n",
      "\u001b[0;31mParamValidationError\u001b[0m: Parameter validation failed:\nInvalid type for parameter Body, value: None, type: <class 'NoneType'>, valid types: <class 'bytes'>, <class 'bytearray'>, file-like object"
     ]
    }
   ],
   "source": [
    "import io\n",
    "pkl_buffer = io.BytesIO()\n",
    "df_key = 'data/5M_df.pkl'\n",
    "pkl_df = df.to_pickle(df_key)\n",
    "s3.Object(bucket,df_key).put(Body=pkl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = 'fakenewscorpus'\n",
    "key = 'data/5M_df.pkl'\n",
    "# obj = s3.get_object(Bucket='bucket', Key='key')\n",
    "df = pickle.loads(s3.Bucket(bucket).Object(key).get()['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33273061724603664"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def balance(df):\n",
    "    n_pos = len(df[df['label']==1])\n",
    "    n_neg = len(df[df['label']==0])\n",
    "    return n_pos, n_neg\n",
    "\n",
    "n_pos, n_neg = balance(df)\n",
    "\n",
    "n_pos/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33258, 66742)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = pd.read_csv('data/sw1k.csv')['term'].to_numpy()\n",
    "\n",
    "sample = df.sample(100000,axis=0)\n",
    "\n",
    "balance(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenize(sample['content'],sw)\n",
    "\n",
    "sample['token']=tokens\n",
    "\n",
    "X = tokens\n",
    "y = sample['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "bow, tf, tfidf, cv, tv = vectorize(X_train,max_features=5000,ngram=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(tfidf).to_csv('data/sample_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf = pd.read_csv('data/sample_tfidf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 5000)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5466"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQ_LENGHT = len(max(X_train, key=len))\n",
    "MAX_SEQ_LENGHT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'fsu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3f157584ab1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mN_FEATURES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGHT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_FEATURES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# check `trunc` has expected shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtrunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             raise ValueError('Shape of sample %s of sequence at position %s '\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvaries\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfastest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mFORTRAN\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcontiguous\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0mmemory\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mvaries\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfastest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'fsu'"
     ]
    }
   ],
   "source": [
    "N_FEATURES = len(bow)\n",
    "X_train_sequences = pad_sequences(X_train, maxlen=MAX_SEQ_LENGHT, value=N_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequences :  [[22], [3], [2], [1], [], [3], [5], [12], [], [7], [14], [7], [3], [5], [5], [3], [], [2], [4], [4], [22], [], [3], [], [15], [4], [15], [], [3], [2], [], [2], [3], [17], [11], [4], [8], [], [3], [5], [12], [], [2], [4], [13], [], [], [16], [3], [8], [8], [3], [20], [3], [17], [], [20], [3], [7], [], [8], [1], [15], [4], [8], [2], [6], [5], [16], [], [2], [9], [1], [], [5], [1], [20], [7], [], [], [3], [5], [5], [4], [14], [5], [10], [6], [5], [16], [], [2], [9], [3], [2], [], [7], [20], [6], [18], [2], [], [9], [3], [7], [], [19], [1], [1], [5], [], [14], [5], [18], [4], [11], [11], [4], [20], [1], [12], [], [19], [17], [], [9], [1], [8], [], [1], [28], [], [19], [4], [17], [18], [8], [6], [1], [5], [12], [], [10], [3], [11], [21], [6], [5], [], [9], [3], [8], [8], [6], [7], [], [4], [5], [], [2], [20], [6], [2], [2], [1], [8], [], [], [], [8], [1], [15], [4], [8], [2], [7], [], [9], [3], [21], [1], [], [7], [14], [8], [18], [3], [10], [1], [12], [], [4], [21], [1], [8], [5], [6], [16], [9], [2], [], [2], [9], [3], [2], [], [2], [9], [1], [], [15], [4], [15], [], [7], [2], [3], [8], [7], [], [], [], [20], [9], [4], [], [3], [5], [5], [4], [14], [5], [10], [1], [12], [], [2], [9], [1], [6], [8], [], [19], [8], [1], [3], [22], [], [14], [15], [], [3], [5], [12], [], [6], [5], [7], [6], [7], [2], [1], [12], [], [6], [2], [], [20], [3], [7], [], [3], [13], [6], [10], [3], [19], [11], [1], [], [11], [3], [7], [2], [], [20], [1], [1], [22], [], [], [], [9], [3], [21], [1], [], [18], [3], [11], [11], [1], [5], [], [4], [14], [2], [], [19], [1], [10], [3], [14], [7], [1], [], [7], [20], [6], [18], [2], [], [9], [3], [7], [], [19], [1], [1], [5], [], [10], [3], [14], [16], [9], [2], [], [10], [4], [7], [17], [6], [5], [16], [], [14], [15], [], [2], [4], [], [2], [9], [1], [], [5], [6], [16], [9], [2], [], [13], [3], [5], [3], [16], [1], [8], [], [3], [10], [2], [4], [8], [], [3], [5], [12], [], [24], [3], [13], [1], [7], [], [19], [4], [5], [12], [], [9], [4], [15], [1], [18], [14], [11], [], [2], [4], [13], [], [9], [6], [12], [12], [11], [1], [7], [2], [4], [5], [], [], [], [2], [9], [1], [8], [1], [], [9], [3], [7], [], [19], [1], [1], [5], [], [5], [4], [], [10], [4], [5], [18], [6], [8], [13], [3], [2], [6], [4], [5], [], [3], [7], [], [4], [18], [], [17], [1], [2], [], [], [19], [14], [2], [], [16], [3], [8], [8], [3], [20], [3], [17], [], [20], [3], [7], [], [35], [14], [6], [10], [22], [], [2], [4], [], [16], [6], [21], [1], [], [9], [1], [8], [], [4], [15], [6], [5], [6], [4], [5], [], [], [], [36], [7], [9], [1], [], [], [7], [20], [6], [18], [2], [], [], [6], [7], [5], [27], [2], [], [16], [4], [6], [5], [16], [], [2], [4], [], [19], [1], [], [7], [9], [4], [8], [2], [], [4], [18], [], [4], [18], [18], [1], [8], [7], [], [37], [], [2], [9], [1], [], [], [], [], [17], [1], [3], [8], [], [4], [11], [12], [], [15], [8], [1], [7], [1], [5], [2], [1], [8], [], [7], [3], [6], [12], [], [], [36], [20], [9], [17], [], [10], [3], [5], [27], [2], [], [7], [9], [1], [], [24], [14], [7], [2], [], [11], [1], [3], [21], [1], [], [2], [4], [13], [], [9], [6], [12], [12], [11], [1], [7], [2], [4], [5], [], [3], [11], [4], [5], [1], [], [18], [4], [8], [], [14], [7], [], [37]] \n",
      "\n",
      "word_index :  {'e': 1, 't': 2, 'a': 3, 'o': 4, 'n': 5, 'i': 6, 's': 7, 'r': 8, 'h': 9, 'c': 10, 'l': 11, 'd': 12, 'm': 13, 'u': 14, 'p': 15, 'g': 16, 'y': 17, 'f': 18, 'b': 19, 'w': 20, 'v': 21, 'k': 22, \"'\": 23, 'j': 24, '1': 25, '2': 26, '’': 27, 'x': 28, '3': 29, 'z': 30, '0': 31, '8': 32, '6': 33, '5': 34, 'q': 35, '“': 36, '”': 37, '…': 38, '‘': 39}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer(num_words = 500)\n",
    "s = df['content']\n",
    "t.fit_on_texts(s)\n",
    "sq = t_temp.texts_to_sequences(r)\n",
    "# print('sequences : ', sq,'\\n')\n",
    "# print('word_index : ',t_temp.word_index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "file must have 'read' and 'readline' attributes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2a8f15a0afe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/5M_df.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: file must have 'read' and 'readline' attributes"
     ]
    }
   ],
   "source": [
    "df = pickle.load('data/5M_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content']\n",
    "y = df['label']\n",
    "t = Tokenizer(num_words=10000)\n",
    "t.fit_on_texts(df['content'])\n",
    "X = t.texts_to_sequences(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_matrix = pad_sequences(X, maxlen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_matrix,y)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2421128, 10000)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 1, 64)             2576640   \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,609,729\n",
      "Trainable params: 2,609,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm_model = Sequential()\n",
    "\n",
    "lstm_model.add(LSTM(units=64, return_sequences=True, input_shape=(1,10000)))\n",
    "lstm_model.add(LSTM(64),)\n",
    "lstm_model.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC','BinaryAccuracy','Recall','Precision'])\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1415846 samples, validate on 400000 samples\n",
      "Epoch 1/50\n",
      "1415846/1415846 [==============================] - 150s 106us/sample - loss: 0.6035 - auc_4: 0.6600 - binary_accuracy: 0.6732 - recall_4: 0.1759 - precision_4: 0.5621 - val_loss: 0.5964 - val_auc_4: 0.6717 - val_binary_accuracy: 0.6779 - val_recall_4: 0.2350 - val_precision_4: 0.5639\n",
      "Epoch 2/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5947 - auc_4: 0.6724 - binary_accuracy: 0.6810 - recall_4: 0.1905 - precision_4: 0.5969 - val_loss: 0.5899 - val_auc_4: 0.6789 - val_binary_accuracy: 0.6840 - val_recall_4: 0.1965 - val_precision_4: 0.6108\n",
      "Epoch 3/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5913 - auc_4: 0.6759 - binary_accuracy: 0.6829 - recall_4: 0.1929 - precision_4: 0.6056 - val_loss: 0.5907 - val_auc_4: 0.6776 - val_binary_accuracy: 0.6815 - val_recall_4: 0.2088 - val_precision_4: 0.5902\n",
      "Epoch 4/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5899 - auc_4: 0.6774 - binary_accuracy: 0.6829 - recall_4: 0.1935 - precision_4: 0.6055 - val_loss: 0.5910 - val_auc_4: 0.6774 - val_binary_accuracy: 0.6835 - val_recall_4: 0.1935 - val_precision_4: 0.6099\n",
      "Epoch 5/50\n",
      "1415846/1415846 [==============================] - 145s 103us/sample - loss: 0.5893 - auc_4: 0.6780 - binary_accuracy: 0.6840 - recall_4: 0.1944 - precision_4: 0.6108 - val_loss: 0.5893 - val_auc_4: 0.6783 - val_binary_accuracy: 0.6837 - val_recall_4: 0.1500 - val_precision_4: 0.6531\n",
      "Epoch 6/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5878 - auc_4: 0.6798 - binary_accuracy: 0.6858 - recall_4: 0.1958 - precision_4: 0.6198 - val_loss: 0.5873 - val_auc_4: 0.6794 - val_binary_accuracy: 0.6853 - val_recall_4: 0.2130 - val_precision_4: 0.6070\n",
      "Epoch 7/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5871 - auc_4: 0.6796 - binary_accuracy: 0.6857 - recall_4: 0.1926 - precision_4: 0.6219 - val_loss: 0.5887 - val_auc_4: 0.6791 - val_binary_accuracy: 0.6837 - val_recall_4: 0.1739 - val_precision_4: 0.6266\n",
      "Epoch 8/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5868 - auc_4: 0.6805 - binary_accuracy: 0.6862 - recall_4: 0.1977 - precision_4: 0.6208 - val_loss: 0.5850 - val_auc_4: 0.6819 - val_binary_accuracy: 0.6874 - val_recall_4: 0.1941 - val_precision_4: 0.6321\n",
      "Epoch 9/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5853 - auc_4: 0.6823 - binary_accuracy: 0.6869 - recall_4: 0.2015 - precision_4: 0.6222 - val_loss: 0.5871 - val_auc_4: 0.6785 - val_binary_accuracy: 0.6856 - val_recall_4: 0.1772 - val_precision_4: 0.6365\n",
      "Epoch 10/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5865 - auc_4: 0.6784 - binary_accuracy: 0.6867 - recall_4: 0.1989 - precision_4: 0.6228 - val_loss: 0.5859 - val_auc_4: 0.6799 - val_binary_accuracy: 0.6875 - val_recall_4: 0.1787 - val_precision_4: 0.6474\n",
      "Epoch 11/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5859 - auc_4: 0.6791 - binary_accuracy: 0.6870 - recall_4: 0.2018 - precision_4: 0.6223 - val_loss: 0.5847 - val_auc_4: 0.6822 - val_binary_accuracy: 0.6880 - val_recall_4: 0.2071 - val_precision_4: 0.6255\n",
      "Epoch 12/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5843 - auc_4: 0.6835 - binary_accuracy: 0.6876 - recall_4: 0.2017 - precision_4: 0.6261 - val_loss: 0.5842 - val_auc_4: 0.6836 - val_binary_accuracy: 0.6870 - val_recall_4: 0.1830 - val_precision_4: 0.6399\n",
      "Epoch 13/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5838 - auc_4: 0.6843 - binary_accuracy: 0.6887 - recall_4: 0.2025 - precision_4: 0.6315 - val_loss: 0.5835 - val_auc_4: 0.6843 - val_binary_accuracy: 0.6894 - val_recall_4: 0.2290 - val_precision_4: 0.6176\n",
      "Epoch 14/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5843 - auc_4: 0.6814 - binary_accuracy: 0.6891 - recall_4: 0.2025 - precision_4: 0.6337 - val_loss: 0.5838 - val_auc_4: 0.6810 - val_binary_accuracy: 0.6892 - val_recall_4: 0.2089 - val_precision_4: 0.6308\n",
      "Epoch 15/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5846 - auc_4: 0.6821 - binary_accuracy: 0.6884 - recall_4: 0.2050 - precision_4: 0.6279 - val_loss: 0.5824 - val_auc_4: 0.6859 - val_binary_accuracy: 0.6892 - val_recall_4: 0.2092 - val_precision_4: 0.6304\n",
      "Epoch 16/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5825 - auc_4: 0.6857 - binary_accuracy: 0.6893 - recall_4: 0.2056 - precision_4: 0.6325 - val_loss: 0.5825 - val_auc_4: 0.6862 - val_binary_accuracy: 0.6894 - val_recall_4: 0.2029 - val_precision_4: 0.6364\n",
      "Epoch 17/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5825 - auc_4: 0.6855 - binary_accuracy: 0.6896 - recall_4: 0.2029 - precision_4: 0.6362 - val_loss: 0.5824 - val_auc_4: 0.6854 - val_binary_accuracy: 0.6879 - val_recall_4: 0.1811 - val_precision_4: 0.6478\n",
      "Epoch 18/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5833 - auc_4: 0.6833 - binary_accuracy: 0.6890 - recall_4: 0.2044 - precision_4: 0.6315 - val_loss: 0.5841 - val_auc_4: 0.6817 - val_binary_accuracy: 0.6884 - val_recall_4: 0.1873 - val_precision_4: 0.6449\n",
      "Epoch 19/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5829 - auc_4: 0.6829 - binary_accuracy: 0.6896 - recall_4: 0.2038 - precision_4: 0.6353 - val_loss: 0.5814 - val_auc_4: 0.6846 - val_binary_accuracy: 0.6903 - val_recall_4: 0.2072 - val_precision_4: 0.6381\n",
      "Epoch 20/50\n",
      "1415846/1415846 [==============================] - 145s 103us/sample - loss: 0.5819 - auc_4: 0.6849 - binary_accuracy: 0.6898 - recall_4: 0.2023 - precision_4: 0.6380 - val_loss: 0.5823 - val_auc_4: 0.6846 - val_binary_accuracy: 0.6898 - val_recall_4: 0.2057 - val_precision_4: 0.6365\n",
      "Epoch 21/50\n",
      "1415846/1415846 [==============================] - 144s 101us/sample - loss: 0.5820 - auc_4: 0.6846 - binary_accuracy: 0.6905 - recall_4: 0.2040 - precision_4: 0.6406 - val_loss: 0.5819 - val_auc_4: 0.6846 - val_binary_accuracy: 0.6898 - val_recall_4: 0.1928 - val_precision_4: 0.6484\n",
      "Epoch 22/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5817 - auc_4: 0.6846 - binary_accuracy: 0.6902 - recall_4: 0.2046 - precision_4: 0.6387 - val_loss: 0.5817 - val_auc_4: 0.6857 - val_binary_accuracy: 0.6902 - val_recall_4: 0.2031 - val_precision_4: 0.6412\n",
      "Epoch 23/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5817 - auc_4: 0.6842 - binary_accuracy: 0.6900 - recall_4: 0.2042 - precision_4: 0.6376 - val_loss: 0.5822 - val_auc_4: 0.6835 - val_binary_accuracy: 0.6889 - val_recall_4: 0.2221 - val_precision_4: 0.6195\n",
      "Epoch 24/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5819 - auc_4: 0.6843 - binary_accuracy: 0.6893 - recall_4: 0.2067 - precision_4: 0.6316 - val_loss: 0.5829 - val_auc_4: 0.6829 - val_binary_accuracy: 0.6892 - val_recall_4: 0.1948 - val_precision_4: 0.6424\n",
      "Epoch 25/50\n",
      "1415846/1415846 [==============================] - 144s 102us/sample - loss: 0.5824 - auc_4: 0.6833 - binary_accuracy: 0.6893 - recall_4: 0.2031 - precision_4: 0.6342 - val_loss: 0.5827 - val_auc_4: 0.6826 - val_binary_accuracy: 0.6895 - val_recall_4: 0.2005 - val_precision_4: 0.6391\n",
      "Epoch 26/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5831 - auc_4: 0.6813 - binary_accuracy: 0.6891 - recall_4: 0.2030 - precision_4: 0.6333 - val_loss: 0.5824 - val_auc_4: 0.6821 - val_binary_accuracy: 0.6887 - val_recall_4: 0.2024 - val_precision_4: 0.6331\n",
      "Epoch 27/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5826 - auc_4: 0.6843 - binary_accuracy: 0.6880 - recall_4: 0.2057 - precision_4: 0.6253 - val_loss: 0.5816 - val_auc_4: 0.6866 - val_binary_accuracy: 0.6888 - val_recall_4: 0.2106 - val_precision_4: 0.6270\n",
      "Epoch 28/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5823 - auc_4: 0.6852 - binary_accuracy: 0.6884 - recall_4: 0.2008 - precision_4: 0.6313 - val_loss: 0.5815 - val_auc_4: 0.6845 - val_binary_accuracy: 0.6895 - val_recall_4: 0.1999 - val_precision_4: 0.6398\n",
      "Epoch 29/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5824 - auc_4: 0.6831 - binary_accuracy: 0.6892 - recall_4: 0.2023 - precision_4: 0.6347 - val_loss: 0.5825 - val_auc_4: 0.6834 - val_binary_accuracy: 0.6895 - val_recall_4: 0.2053 - val_precision_4: 0.6355\n",
      "Epoch 30/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5831 - auc_4: 0.6822 - binary_accuracy: 0.6895 - recall_4: 0.2044 - precision_4: 0.6348 - val_loss: 0.5831 - val_auc_4: 0.6818 - val_binary_accuracy: 0.6904 - val_recall_4: 0.2068 - val_precision_4: 0.6390\n",
      "Epoch 31/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5831 - auc_4: 0.6818 - binary_accuracy: 0.6899 - recall_4: 0.2031 - precision_4: 0.6383 - val_loss: 0.5825 - val_auc_4: 0.6828 - val_binary_accuracy: 0.6891 - val_recall_4: 0.1982 - val_precision_4: 0.6391\n",
      "Epoch 32/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5836 - auc_4: 0.6800 - binary_accuracy: 0.6893 - recall_4: 0.2050 - precision_4: 0.6326 - val_loss: 0.5825 - val_auc_4: 0.6819 - val_binary_accuracy: 0.6896 - val_recall_4: 0.2007 - val_precision_4: 0.6395\n",
      "Epoch 33/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5829 - auc_4: 0.6819 - binary_accuracy: 0.6896 - recall_4: 0.2034 - precision_4: 0.6360 - val_loss: 0.5837 - val_auc_4: 0.6805 - val_binary_accuracy: 0.6903 - val_recall_4: 0.2149 - val_precision_4: 0.6320\n",
      "Epoch 34/50\n",
      "1415846/1415846 [==============================] - 145s 103us/sample - loss: 0.5829 - auc_4: 0.6818 - binary_accuracy: 0.6892 - recall_4: 0.2042 - precision_4: 0.6329 - val_loss: 0.5819 - val_auc_4: 0.6832 - val_binary_accuracy: 0.6894 - val_recall_4: 0.1902 - val_precision_4: 0.6485\n",
      "Epoch 35/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5816 - auc_4: 0.6832 - binary_accuracy: 0.6902 - recall_4: 0.2074 - precision_4: 0.6362 - val_loss: 0.5830 - val_auc_4: 0.6840 - val_binary_accuracy: 0.6906 - val_recall_4: 0.2146 - val_precision_4: 0.6340\n",
      "Epoch 36/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5822 - auc_4: 0.6825 - binary_accuracy: 0.6894 - recall_4: 0.2127 - precision_4: 0.6273 - val_loss: 0.5815 - val_auc_4: 0.6834 - val_binary_accuracy: 0.6895 - val_recall_4: 0.2132 - val_precision_4: 0.6291\n",
      "Epoch 37/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5815 - auc_4: 0.6831 - binary_accuracy: 0.6896 - recall_4: 0.2084 - precision_4: 0.6317 - val_loss: 0.5812 - val_auc_4: 0.6847 - val_binary_accuracy: 0.6890 - val_recall_4: 0.2082 - val_precision_4: 0.6298\n",
      "Epoch 38/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5808 - auc_4: 0.6848 - binary_accuracy: 0.6898 - recall_4: 0.2101 - precision_4: 0.6316 - val_loss: 0.5809 - val_auc_4: 0.6847 - val_binary_accuracy: 0.6894 - val_recall_4: 0.2023 - val_precision_4: 0.6371\n",
      "Epoch 39/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5800 - auc_4: 0.6867 - binary_accuracy: 0.6902 - recall_4: 0.2116 - precision_4: 0.6330 - val_loss: 0.5804 - val_auc_4: 0.6865 - val_binary_accuracy: 0.6889 - val_recall_4: 0.2109 - val_precision_4: 0.6271\n",
      "Epoch 40/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5818 - auc_4: 0.6836 - binary_accuracy: 0.6891 - recall_4: 0.2073 - precision_4: 0.6301 - val_loss: 0.5823 - val_auc_4: 0.6840 - val_binary_accuracy: 0.6887 - val_recall_4: 0.2081 - val_precision_4: 0.6281\n",
      "Epoch 41/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5822 - auc_4: 0.6836 - binary_accuracy: 0.6891 - recall_4: 0.2087 - precision_4: 0.6288 - val_loss: 0.5829 - val_auc_4: 0.6844 - val_binary_accuracy: 0.6890 - val_recall_4: 0.2138 - val_precision_4: 0.6259\n",
      "Epoch 42/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5820 - auc_4: 0.6832 - binary_accuracy: 0.6890 - recall_4: 0.2081 - precision_4: 0.6289 - val_loss: 0.5825 - val_auc_4: 0.6837 - val_binary_accuracy: 0.6890 - val_recall_4: 0.1979 - val_precision_4: 0.6384\n",
      "Epoch 43/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5814 - auc_4: 0.6840 - binary_accuracy: 0.6900 - recall_4: 0.2092 - precision_4: 0.6334 - val_loss: 0.5820 - val_auc_4: 0.6838 - val_binary_accuracy: 0.6906 - val_recall_4: 0.2096 - val_precision_4: 0.6381\n",
      "Epoch 44/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5807 - auc_4: 0.6846 - binary_accuracy: 0.6903 - recall_4: 0.2060 - precision_4: 0.6378 - val_loss: 0.5807 - val_auc_4: 0.6849 - val_binary_accuracy: 0.6908 - val_recall_4: 0.2017 - val_precision_4: 0.6459\n",
      "Epoch 45/50\n",
      "1415846/1415846 [==============================] - 145s 103us/sample - loss: 0.5804 - auc_4: 0.6849 - binary_accuracy: 0.6906 - recall_4: 0.2027 - precision_4: 0.6425 - val_loss: 0.5804 - val_auc_4: 0.6850 - val_binary_accuracy: 0.6908 - val_recall_4: 0.2160 - val_precision_4: 0.6340\n",
      "Epoch 46/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5807 - auc_4: 0.6840 - binary_accuracy: 0.6911 - recall_4: 0.2053 - precision_4: 0.6433 - val_loss: 0.5815 - val_auc_4: 0.6831 - val_binary_accuracy: 0.6897 - val_recall_4: 0.1967 - val_precision_4: 0.6438\n",
      "Epoch 47/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5815 - auc_4: 0.6827 - binary_accuracy: 0.6896 - recall_4: 0.2060 - precision_4: 0.6338 - val_loss: 0.5818 - val_auc_4: 0.6819 - val_binary_accuracy: 0.6882 - val_recall_4: 0.1987 - val_precision_4: 0.6330\n",
      "Epoch 48/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5811 - auc_4: 0.6832 - binary_accuracy: 0.6892 - recall_4: 0.2062 - precision_4: 0.6316 - val_loss: 0.5803 - val_auc_4: 0.6850 - val_binary_accuracy: 0.6903 - val_recall_4: 0.2048 - val_precision_4: 0.6400\n",
      "Epoch 49/50\n",
      "1415846/1415846 [==============================] - 146s 103us/sample - loss: 0.5805 - auc_4: 0.6844 - binary_accuracy: 0.6902 - recall_4: 0.2074 - precision_4: 0.6361 - val_loss: 0.5806 - val_auc_4: 0.6844 - val_binary_accuracy: 0.6891 - val_recall_4: 0.1962 - val_precision_4: 0.6408\n",
      "Epoch 50/50\n",
      "1415846/1415846 [==============================] - 145s 102us/sample - loss: 0.5806 - auc_4: 0.6851 - binary_accuracy: 0.6901 - recall_4: 0.2042 - precision_4: 0.6383 - val_loss: 0.5798 - val_auc_4: 0.6861 - val_binary_accuracy: 0.6904 - val_recall_4: 0.2011 - val_precision_4: 0.6443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1817af15c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.fit(X_train[:-400000], y_train[:-400000], \n",
    "          epochs=50, batch_size=128, verbose=1,\n",
    "          validation_data=(X_train[-400000:], y_train[-400000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/sample_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('saved_model/sample_model',compile = False)\n",
    "tfidf = pd.read_csv('data/sample_tfidf.csv')\n",
    "X_train = tfidf.set_ind\n",
    "y_train = sample['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('saved_model/lstm_model_5M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605282/605282 [==============================] - 49s 81us/sample - loss: 0.5805 - auc_4: 0.6856 - binary_accuracy: 0.6895 - recall_4: 0.1988 - precision_4: 0.6417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5804980644907652, 0.6856179, 0.6894588, 0.19880907, 0.641698]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.evaluate(X_test, y_test, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [' '.join(row) for row in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 37s 15ms/sample - loss: 0.6377 - auc_14: 0.5000 - binary_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.637664122581482, 0.5, 0.6656]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 500)               2500500   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 2,501,001\n",
      "Trainable params: 2,501,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    " \n",
    "model2.add(Dense(units=500, activation='relu', input_dim=5000))\n",
    "model2.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['AUC','BinaryAccuracy','Recall','Precision'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 65000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "65000/65000 [==============================] - 4s 56us/sample - loss: 0.3315 - auc_2: 0.9143 - binary_accuracy: 0.8586 - recall: 0.6843 - precision: 0.8681 - val_loss: 0.2754 - val_auc_2: 0.9386 - val_binary_accuracy: 0.8855 - val_recall: 0.7291 - val_precision: 0.9064\n",
      "Epoch 2/30\n",
      "65000/65000 [==============================] - 3s 51us/sample - loss: 0.2491 - auc_2: 0.9514 - binary_accuracy: 0.8976 - recall: 0.7859 - precision: 0.8975 - val_loss: 0.2642 - val_auc_2: 0.9423 - val_binary_accuracy: 0.8889 - val_recall: 0.7557 - val_precision: 0.8919\n",
      "Epoch 3/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.2161 - auc_2: 0.9637 - binary_accuracy: 0.9110 - recall: 0.8133 - precision: 0.9133 - val_loss: 0.2657 - val_auc_2: 0.9431 - val_binary_accuracy: 0.8889 - val_recall: 0.7884 - val_precision: 0.8639\n",
      "Epoch 4/30\n",
      "65000/65000 [==============================] - 3s 53us/sample - loss: 0.1778 - auc_2: 0.9763 - binary_accuracy: 0.9300 - recall: 0.8503 - precision: 0.9361 - val_loss: 0.2706 - val_auc_2: 0.9440 - val_binary_accuracy: 0.8905 - val_recall: 0.7884 - val_precision: 0.8685\n",
      "Epoch 5/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.1342 - auc_2: 0.9873 - binary_accuracy: 0.9526 - recall: 0.8970 - precision: 0.9598 - val_loss: 0.2783 - val_auc_2: 0.9443 - val_binary_accuracy: 0.8901 - val_recall: 0.7963 - val_precision: 0.8611\n",
      "Epoch 6/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0886 - auc_2: 0.9950 - binary_accuracy: 0.9753 - recall: 0.9443 - precision: 0.9818 - val_loss: 0.3010 - val_auc_2: 0.9430 - val_binary_accuracy: 0.8897 - val_recall: 0.8029 - val_precision: 0.8548\n",
      "Epoch 7/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0532 - auc_2: 0.9982 - binary_accuracy: 0.9893 - recall: 0.9733 - precision: 0.9947 - val_loss: 0.3173 - val_auc_2: 0.9410 - val_binary_accuracy: 0.8927 - val_recall: 0.7947 - val_precision: 0.8697\n",
      "Epoch 8/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0310 - auc_2: 0.9994 - binary_accuracy: 0.9951 - recall: 0.9864 - precision: 0.9990 - val_loss: 0.3489 - val_auc_2: 0.9386 - val_binary_accuracy: 0.8925 - val_recall: 0.7929 - val_precision: 0.8706\n",
      "Epoch 9/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0193 - auc_2: 0.9998 - binary_accuracy: 0.9968 - recall: 0.9910 - precision: 0.9994 - val_loss: 0.3660 - val_auc_2: 0.9374 - val_binary_accuracy: 0.8912 - val_recall: 0.8023 - val_precision: 0.8595\n",
      "Epoch 10/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0133 - auc_2: 0.9999 - binary_accuracy: 0.9973 - recall: 0.9925 - precision: 0.9995 - val_loss: 0.3973 - val_auc_2: 0.9356 - val_binary_accuracy: 0.8896 - val_recall: 0.8083 - val_precision: 0.8505\n",
      "Epoch 11/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0102 - auc_2: 0.9999 - binary_accuracy: 0.9975 - recall: 0.9931 - precision: 0.9996 - val_loss: 0.4181 - val_auc_2: 0.9329 - val_binary_accuracy: 0.8899 - val_recall: 0.8077 - val_precision: 0.8518\n",
      "Epoch 12/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0086 - auc_2: 0.9999 - binary_accuracy: 0.9977 - recall: 0.9934 - precision: 0.9997 - val_loss: 0.4423 - val_auc_2: 0.9307 - val_binary_accuracy: 0.8898 - val_recall: 0.8047 - val_precision: 0.8538\n",
      "Epoch 13/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0075 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9936 - precision: 0.9999 - val_loss: 0.4604 - val_auc_2: 0.9285 - val_binary_accuracy: 0.8904 - val_recall: 0.8056 - val_precision: 0.8547\n",
      "Epoch 14/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0070 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9936 - precision: 0.9999 - val_loss: 0.4726 - val_auc_2: 0.9287 - val_binary_accuracy: 0.8894 - val_recall: 0.8117 - val_precision: 0.8475\n",
      "Epoch 15/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0066 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9937 - precision: 0.9999 - val_loss: 0.4904 - val_auc_2: 0.9278 - val_binary_accuracy: 0.8886 - val_recall: 0.8096 - val_precision: 0.8469\n",
      "Epoch 16/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0063 - auc_2: 0.9999 - binary_accuracy: 0.9978 - recall: 0.9937 - precision: 0.9999 - val_loss: 0.5151 - val_auc_2: 0.9243 - val_binary_accuracy: 0.8926 - val_recall: 0.7963 - val_precision: 0.8682\n",
      "Epoch 17/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0060 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5225 - val_auc_2: 0.9244 - val_binary_accuracy: 0.8920 - val_recall: 0.8008 - val_precision: 0.8629\n",
      "Epoch 18/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0059 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5355 - val_auc_2: 0.9237 - val_binary_accuracy: 0.8910 - val_recall: 0.8035 - val_precision: 0.8580\n",
      "Epoch 19/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0058 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5525 - val_auc_2: 0.9217 - val_binary_accuracy: 0.8927 - val_recall: 0.8029 - val_precision: 0.8632\n",
      "Epoch 20/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0058 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 0.9999 - val_loss: 0.5601 - val_auc_2: 0.9224 - val_binary_accuracy: 0.8910 - val_recall: 0.8053 - val_precision: 0.8566\n",
      "Epoch 21/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5750 - val_auc_2: 0.9205 - val_binary_accuracy: 0.8920 - val_recall: 0.8053 - val_precision: 0.8594\n",
      "Epoch 22/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5818 - val_auc_2: 0.9196 - val_binary_accuracy: 0.8913 - val_recall: 0.8029 - val_precision: 0.8593\n",
      "Epoch 23/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.5880 - val_auc_2: 0.9200 - val_binary_accuracy: 0.8905 - val_recall: 0.8080 - val_precision: 0.8532\n",
      "Epoch 24/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0132 - auc_2: 0.9997 - binary_accuracy: 0.9954 - recall: 0.9901 - precision: 0.9963 - val_loss: 0.5385 - val_auc_2: 0.9189 - val_binary_accuracy: 0.8848 - val_recall: 0.7947 - val_precision: 0.8475\n",
      "Epoch 25/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0111 - auc_2: 0.9999 - binary_accuracy: 0.9966 - recall: 0.9920 - precision: 0.9980 - val_loss: 0.5462 - val_auc_2: 0.9218 - val_binary_accuracy: 0.8874 - val_recall: 0.8035 - val_precision: 0.8481\n",
      "Epoch 26/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0061 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5754 - val_auc_2: 0.9189 - val_binary_accuracy: 0.8910 - val_recall: 0.7963 - val_precision: 0.8636\n",
      "Epoch 27/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 1.0000 - binary_accuracy: 0.9979 - recall: 0.9937 - precision: 1.0000 - val_loss: 0.5954 - val_auc_2: 0.9174 - val_binary_accuracy: 0.8913 - val_recall: 0.7956 - val_precision: 0.8649\n",
      "Epoch 28/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0057 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6070 - val_auc_2: 0.9167 - val_binary_accuracy: 0.8917 - val_recall: 0.7975 - val_precision: 0.8646\n",
      "Epoch 29/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0056 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6153 - val_auc_2: 0.9165 - val_binary_accuracy: 0.8913 - val_recall: 0.8005 - val_precision: 0.8611\n",
      "Epoch 30/30\n",
      "65000/65000 [==============================] - 3s 52us/sample - loss: 0.0056 - auc_2: 0.9999 - binary_accuracy: 0.9979 - recall: 0.9938 - precision: 1.0000 - val_loss: 0.6179 - val_auc_2: 0.9176 - val_binary_accuracy: 0.8897 - val_recall: 0.8050 - val_precision: 0.8533\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f87905ce390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(tfidf[:-10000], y_train[:-10000], \n",
    "          epochs=30, batch_size=128, verbose=1,\n",
    "          validation_data=(tfidf[-10000:], y_train[-10000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('saved_model/sample_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 59us/sample - loss: 0.6468 - auc_2: 0.9164 - binary_accuracy: 0.8898 - recall: 0.8058 - precision: 0.8510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6467978135927022, 0.9164012, 0.88976, 0.8058158, 0.8509572]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(tfidf_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = 0.81"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
